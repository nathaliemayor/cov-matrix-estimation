diag(diag(Psi))
} else if(method == "factor3"){
# 3-factors model (market, HML, SMB)
sigma_hat <- beta %*%
cov(F_[,-1]) %*%
t(beta) +
diag(diag(Psi))
}
} else if (method == "sample") {
# sigma_hat = cov(as.data.frame(data), method = "pearson")
sigma_hat <- (t(as.matrix(data)) %*% as.matrix(data)) / (dim(data)[1]-1)
}
return(sigma_hat)
}
get_portfolio_metrics <- function (
stock_returns,
cov_est_method,
roll,
portfolio_optimization,
short = TRUE,
frequency = "monthly",
factor_returns = NULL
) {
if(frequency == "monthly"){
freq <- 12
multiplicator <- 1
}else if(frequency == "daily"){
freq <- 252
# 21 trading days in one month
multiplicator <- 21
}
training_data <- stock_returns[
(roll*multiplicator):(training_period*multiplicator+roll*multiplicator-1),
-1
]
training_date <- stock_returns[
(roll*multiplicator):(training_period*multiplicator+roll*multiplicator-1),
1
]
# rf <- window(TNX,
#            start = first(training_date),
#            end = last(training_date))$TNX.Adjusted %>%
# # get average monthly rate, percentage to decimal
# mean(na.rm = T)/freq
rf <- 0.42
if(cov_est_method %in% c("factor1", "factor3")){
training_factor_data <- factor_returns[
(roll*multiplicator):(training_period*multiplicator+roll*multiplicator-1),
-1
]
} else {
training_factor_data <- NULL
}
testing_data <- stock_returns[
((training_period+roll)*multiplicator):
(((training_period+roll+rolling_period)*multiplicator)-1),
]
date_test <- testing_data[,1]
# rf_sr <- window(TNX,
#                 start = first(date_test),
#                 end = last(date_test))$TNX.Adjusted %>%
#   # get average monthly rate, percentage to decimal
#   mean(na.rm = T)/freq
# covariance estimation
## linear shrinkage
rf_sr <- 0.5/multiplicator
if (!cov_est_method == "equal_weights") {
sigma_hat = get_covariance_estimate(
method = cov_est_method,
data = training_data,
factor_data = training_factor_data
)
}
# compute optimal portfolio weights
if (cov_est_method == "equal_weights") {
optimal_weights <- equal_weights(training_data)
} else {
inverse_sigma_hat = solve(sigma_hat)
if (portfolio_optimization == "tangent") {
# tangent portfolio from Markowitz formula
excess_er_hat <- colMeans(training_data - rf)
optimal_weights <- (inverse_sigma_hat %*% excess_er_hat)/
sum(inverse_sigma_hat %*% excess_er_hat)
if (short == FALSE) {
optimal_weights <- quadprog::solve.QP(
inverse_sigma_hat,
excess_er_hat,
cbind(rep(1, length(excess_er_hat)),
diag(1, nrow = length(excess_er_hat))),
c(1, rep(0, length(excess_er_hat))),
)$solution
}
} else if (portfolio_optimization == "minvar") {
# minvar portfolio from Markowitz formula
v_ones <- rep(1, dim(inverse_sigma_hat)[1])
optimal_weights <- as.numeric(inverse_sigma_hat %*% v_ones)/
as.numeric(v_ones %*% inverse_sigma_hat %*% v_ones)
}
}
period_returns <- rowSums(testing_data[,-1]*optimal_weights) %>%
tibble(date=date_test, returns = .*multiplicator)
ptf_variance <- t(as.matrix(optimal_weights)) %*%
as.matrix(cov(testing_data[,-1])) %*%
as.matrix(optimal_weights)
ptf_sd <- sqrt(ptf_variance)*sqrt(multiplicator)
SR <- ((mean(period_returns$returns)-rf_sr)/ptf_sd)*
sqrt(freq)*
sqrt(multiplicator)
# results <- period_returns
results = list(period_returns, ptf_sd, SR, optimal_weights)
}
bootstrap_cov_estimates <- function(
roll,
n_bootstraps,
cov_est_method,
data = ff100_data$monthly,
frequency = "monthly"
) {
if (frequency == "monthly") {
mutiplicator <- 1
} else if (frequency == "daily") {
# 21 trading days within a month
multiplicator <- 21
}
stock_returns <- bootstrapped_portfolios(data, n_bootstraps)
test_rolling_bootstrap <- pmap(
crossing(stock_returns, roll),
get_portfolio_metrics,
cov_est_method = cov_est_method,
portfolio_optimization = "tangent",
short = TRUE,
factor_returns = factors,
frequency = frequency
)
names(test_rolling_bootstrap) <- rep(
1:n_bootstraps,
each=length(roll)
)
results_by_bootstrap <- lapply(
seq(1,(n_bootstraps-1)*length(roll)+1, length(roll)),
function(x)
test_rolling_bootstrap[x:(x+length(roll)-1)]
)
names(results_by_bootstrap) <- 1:n_bootstraps
all_avg_returns_bootstrap <- lapply(1:n_bootstraps, function(x)
results_by_bootstrap[[x]] %>%
map_depth(1,1) %>%
reduce(rbind) %>%
filter(!is.na(returns)) %>%
dplyr::summarise(mean = mean(returns)*multiplicator)
) %>%
unlist %>%
reduce(append)
all_avg_sd_bootstrap <- lapply(1:n_bootstraps, function(x)
results_by_bootstrap[[x]] %>%
map_depth(1,2) %>%
reduce(append) %>%
na.omit %>%
mean*sqrt(multiplicator)) %>%
reduce(append)
df <- data.frame(method = cov_est_method,
returns=all_avg_returns_bootstrap,
sd = all_avg_sd_bootstrap)
return(df)
}
test_daily <- pmap(
tibble(data = ff100_data, frequency = c("monthly", "daily")),
bootstrap_cov_estimates,
roll = roll,
n_bootstraps = 100,
cov_est_method = "sample"
)
test_daily
tibble(data = ff100_data, frequency = c("monthly", "daily"))
test_daily
test_daily$daily <- test_daily$daily %>% mutate(method = "sample_daily")
test_daily %>%
reduce(rbind) %>%
ggplot(aes(x=sd*sqrt(21), y = returns*21)) +
geom_point()
test_daily %>%
reduce(rbind) %>%
ggplot(aes(x=sd, y = returns, color = "method")) +
geom_point()
test_daily %>%
reduce(rbind) %>%
ggplot(aes(x=sd, y = returns, color = method)) +
geom_point()
test_daily %>%
reduce(rbind) %>%
filter(returns < 50 & sd <100) %>%
ggplot(aes(x=sd, y = returns, color = method)) +
geom_point()
test_daily %>%
reduce(rbind) %>%
filter(returns < 50 & sd < 200) %>%
ggplot(aes(x=sd, y = returns, color = method)) +
geom_point()
get_portfolio_metrics <- function (
stock_returns,
cov_est_method,
roll,
portfolio_optimization,
short = TRUE,
frequency = "monthly",
factor_returns = NULL
) {
if(frequency == "monthly"){
freq <- 12
multiplicator <- 1
}else if(frequency == "daily"){
freq <- 252
# 21 trading days in one month
multiplicator <- 21
}
training_data <- stock_returns[
(roll*multiplicator):(training_period*multiplicator+roll*multiplicator-1),
-1
]
training_date <- stock_returns[
(roll*multiplicator):(training_period*multiplicator+roll*multiplicator-1),
1
]
# rf <- window(TNX,
#            start = first(training_date),
#            end = last(training_date))$TNX.Adjusted %>%
# # get average monthly rate, percentage to decimal
# mean(na.rm = T)/freq
rf <- 0.42
if(cov_est_method %in% c("factor1", "factor3")){
training_factor_data <- factor_returns[
(roll*multiplicator):(training_period*multiplicator+roll*multiplicator-1),
-1
]
} else {
training_factor_data <- NULL
}
testing_data <- stock_returns[
((training_period+roll)*multiplicator):
(((training_period+roll+rolling_period)*multiplicator)-1),
]
date_test <- testing_data[,1]
# rf_sr <- window(TNX,
#                 start = first(date_test),
#                 end = last(date_test))$TNX.Adjusted %>%
#   # get average monthly rate, percentage to decimal
#   mean(na.rm = T)/freq
# covariance estimation
## linear shrinkage
rf_sr <- 0.5/multiplicator
if (!cov_est_method == "equal_weights") {
sigma_hat = get_covariance_estimate(
method = cov_est_method,
data = training_data,
factor_data = training_factor_data
)
}
# compute optimal portfolio weights
if (cov_est_method == "equal_weights") {
optimal_weights <- equal_weights(training_data)
} else {
inverse_sigma_hat = solve(sigma_hat)
if (portfolio_optimization == "tangent") {
# tangent portfolio from Markowitz formula
excess_er_hat <- colMeans(training_data - rf)
optimal_weights <- (inverse_sigma_hat %*% excess_er_hat)/
sum(inverse_sigma_hat %*% excess_er_hat)
if (short == FALSE) {
optimal_weights <- quadprog::solve.QP(
inverse_sigma_hat,
excess_er_hat,
cbind(rep(1, length(excess_er_hat)),
diag(1, nrow = length(excess_er_hat))),
c(1, rep(0, length(excess_er_hat))),
)$solution
}
} else if (portfolio_optimization == "minvar") {
# minvar portfolio from Markowitz formula
v_ones <- rep(1, dim(inverse_sigma_hat)[1])
optimal_weights <- as.numeric(inverse_sigma_hat %*% v_ones)/
as.numeric(v_ones %*% inverse_sigma_hat %*% v_ones)
}
}
period_returns <- rowSums(testing_data[,-1]*optimal_weights) %>%
tibble(date=date_test, returns = .*multiplicator)
ptf_variance <- t(as.matrix(optimal_weights)) %*%
as.matrix(cov(testing_data[,-1])) %*%
as.matrix(optimal_weights)
ptf_sd <- sqrt(ptf_variance)*sqrt(multiplicator)
SR <- ((mean(period_returns$returns)-rf_sr)/ptf_sd)*
sqrt(freq)*
sqrt(multiplicator)
# results <- period_returns
results = list(period_returns, ptf_sd, SR, optimal_weights)
}
bootstrap_cov_estimates <- function(
roll,
n_bootstraps,
cov_est_method,
data = ff100_data$monthly,
frequency = "monthly"
) {
stock_returns <- bootstrapped_portfolios(data, n_bootstraps)
test_rolling_bootstrap <- pmap(
crossing(stock_returns, roll),
get_portfolio_metrics,
cov_est_method = cov_est_method,
portfolio_optimization = "tangent",
short = TRUE,
factor_returns = factors,
frequency = frequency
)
names(test_rolling_bootstrap) <- rep(
1:n_bootstraps,
each=length(roll)
)
results_by_bootstrap <- lapply(
seq(1,(n_bootstraps-1)*length(roll)+1, length(roll)),
function(x)
test_rolling_bootstrap[x:(x+length(roll)-1)]
)
names(results_by_bootstrap) <- 1:n_bootstraps
all_avg_returns_bootstrap <- lapply(1:n_bootstraps, function(x)
results_by_bootstrap[[x]] %>%
map_depth(1,1) %>%
reduce(rbind) %>%
filter(!is.na(returns)) %>%
dplyr::summarise(mean = mean(returns))
) %>%
unlist %>%
reduce(append)
all_avg_sd_bootstrap <- lapply(1:n_bootstraps, function(x)
results_by_bootstrap[[x]] %>%
map_depth(1,2) %>%
reduce(append) %>%
na.omit %>%
mean) %>%
reduce(append)
df <- data.frame(method = cov_est_method,
returns=all_avg_returns_bootstrap,
sd = all_avg_sd_bootstrap)
return(df)
}
test_daily <- pmap(
tibble(data = ff100_data, frequency = c("monthly", "daily")),
bootstrap_cov_estimates,
roll = roll,
n_bootstraps = 100,
cov_est_method = "sample"
)
data <- ff100_data$monthly
penalization_type <- "L1"
set.seed(123)  # Set seed for reproducibility
num_folds <- 10  # Number of folds for cross-validation
# Create indices for cross-validation
fold_indices <- sample(rep(1:num_folds, length.out = nrow(data)))
# Function to get data for a specific fold
get_fold_data <- function(fold_num) {
return(data[fold_indices == fold_num, ])
}
# Perform cross-validation for L1 and L2 penalization
cv_results <- lapply(c("L1", "L2"), function(penalty_type) {
lapply(1:num_folds, function(fold) {
# Get training data for the current fold
training_data <- data[fold_indices != fold, ]
# Get validation data for the current fold
validation_data <- get_fold_data(fold)
# Perform penalized covariance matrix estimation
CCCP(
training_data,
lambda = NULL,
type = penalty_type,
validation_data = validation_data
)$obj
})
})
# Perform cross-validation for L1 and L2 penalization
cv_results <- lapply(c("L1", "L2"), function(penalty_type) {
lapply(1:num_folds, function(fold) {
# Get training data for the current fold
training_data <- data[fold_indices != fold, ]
# Get validation data for the current fold
validation_data <- get_fold_data(fold)
# Perform penalized covariance matrix estimation
cccp(
training_data,
lambda = NULL,
type = penalty_type,
validation_data = validation_data
)$obj
})
})
cv_results <- lapply(c("L1", "L2"), function(penalty_type) {
lapply(1:num_folds, function(fold) {
# Get training data for the current fold
training_data <- data[fold_indices != fold, ]
# Get validation data for the current fold
validation_data <- get_fold_data(fold)
# Perform penalized covariance matrix estimation
result <- cccp(training_data, penalty = penalty_type)
# Obtain the objective value for the validation set
obj_value <- CCCP_objective(result, validation_data)
return(obj_value)
})
})
library(cvms)
library(cvms)
library(cvms)
library(quantmod)
library(corpcor)
library(covTest)
library(forestFloor)
library(nlme)
library(parallel)
library(qrmtools)
library(MASS)
install.packages("cvms")
install.packages("covTest")
install.packages("forestFloor")
install.packages("qrmtools")
library(cvms)
library(quantmod)
library(corpcor)
library(covTest)
library(forestFloor)
library(nlme)
library(parallel)
library(qrmtools)
library(MASS)
# ------------------------------------------------------------------------------
#                 PREAMBLE - LOAD PACKAGES AND USER DEFINED FUNCTIONS
# ------------------------------------------------------------------------------
# install and load local libraries
local_libs <- list.files("lib", full.names = T)
lapply(local_libs[1], install.packages, repos=NULL, type="source")
library(cvms)
library(quantmod)
library(corpcor)
library(covTest)
local_libs <- list.files("lib", full.names = T)
lapply(local_libs[1], install.packages, repos=NULL, type="source")
# general
library(plyr)
library(tidyverse)
library(xts)
library(zoo)
library(lubridate)
library(conflicted)
# plotting
library(ggalt)
library(extrafont)
library(plotly)
# covariance specific
library(cccp)
library(huge)           # glasso, RIC
library(cvCovEst)
library(rrcov)          # CovMcd and CovMve
library(tawny)
library(tawny.types)
library(covmat)
library(corpcor)
library(CovTools)       # Oracle
library(covFactorModel) # factor models
# finance specific
library(tidyquant)
library(quantmod)
# math/ stats tools
library(quadprog)
library(MASS)
library(StatPerMeCo)
# remotes::install_github("MatthewBJane/theme_park")
library(ThemePark)
library(ggrepel)
# reslove confilcts
conflict_prefer("filter", "dplyr")
conflict_prefer("select", "dplyr")
conflict_prefer("rename", "dplyr")
conflicts_prefer(stats::lag)
conflict_prefer("first", "dplyr")
conflicts_prefer(dplyr::last)
conflicts_prefer(plyr::mutate)
# load own functions
# load Ledoit-Wolf functions
lapply(
c(
list.files("functions", full.names = TRUE),
list.files("covShrinkage-main", pattern = ".R", full.names = T)
),
source
) %>% invisible
library(cvms)
library(quantmod)
library(corpcor)
library(covTest)
library(forestFloor)
library(nlme)
library(parallel)
library(qrmtools)
library(MASS)
penalized_portfolio <- function(returns, lambda, penalty = "L2") {
# Compute the sample covariance matrix
S <- cov(returns)
# Apply L1 or L2 penalty
if (penalty == "L1") {
cov_matrix <- cvms::cvms(S, alpha = 1, lambda = lambda)
} else if (penalty == "L2") {
cov_matrix <- cvms::cvms(S, alpha = 0, lambda = lambda)
} else {
stop("Invalid penalty type. Choose 'L1' or 'L2'.")
}
return(cov_matrix)
}
